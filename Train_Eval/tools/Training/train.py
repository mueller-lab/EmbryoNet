#=======================================================================================================================
#Copyright
#=======================================================================================================================
# Copyright (C) 2021 Matvey Safroshkin, Grigory Arutyunov, Patrick Mueller,
# Computer Vision Studio and Friedrich Miescher Laboratory of the Max Planck Society
# This software is distributed under the terms of the GNU General Public License
#=======================================================================================================================

import torch
import torch.nn.functional as F
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR

from Datasets.BalanceDatasets import get_datasets
from Model.Embryo_severe_model import get_model
from Training.get_embryo_mappers import get_augmentation_mappers
from Training.embryo_mappers import MapDataset
import Training.embryo_mappers as EM
from Training.create_embryo_mappers_json import create_embryo_mappers_list

import argparse
import os

from tensorboardX import SummaryWriter

def train(model, device, train_loader, optimizer, epoch):
    model.to(device)
    model.train()
    epoch_len = len(train_loader)
    print("epoch_len : ", epoch_len)
    for iter, sample in enumerate(train_loader):
        image = sample['image']
        prob = sample['prob']
        age = sample['age']
        prob.requires_grad = True
        data, age, prob = image.to(device), age.to(device), prob.to(device)
        optimizer.zero_grad()
        output_prob = model(data, age)
        print ("output_len : "+ str((output_prob.shape)) + "  prob len: " + str((prob.shape)))
        label = torch.argmax(prob, dim=-1)
   #     print(data.shape)
        loss_prob = F.cross_entropy(output_prob, label).sum(dim=0)
   #     print("loss_prob : ", loss_prob)
        loss = loss_prob
        loss.backward()
        #print("itt : ", iter, " from ",epoch_len)
        print(loss)

        writer.add_scalar('loss', loss, iter + epoch * epoch_len) #shifted loss #deprecated
        #writer.add_scalar('loss', loss, iter)

        optimizer.step()


def map_augmentated_dataset(epoch,  num_mappers, optimizer, scheduler,):
    """
    Filter LVIS instance segmentation annotations to remove all categories that are not included in
    COCO. The new json files can be used to evaluate COCO AP using `lvis-api`. The category ids in
    the output json are the incontiguous COCO dataset ids.
    Args:
        input_filename (str): path to the LVIS json file.
        output_filename (str): path to the COCOfied json file.
    """

    combined_mapper_list = get_augmentation_mappers(epoch, create_embryo_mappers_list())
    combined_mapper_func = EM.CombinedMapperFunc(combined_mapper_list)
    new_num_mappers = 0
    for elem in combined_mapper_list:
        new_num_mappers += len(elem)
    if num_mappers !=new_num_mappers:
        optimizer = optim.Adam(EmbryoNet2_model.parameters(), lr=1e-3)
        scheduler = StepLR(optimizer, step_size=1)
    train_embryo_dataset_concat_mapped = MapDataset(train_balanced_embryoDatasetConcat, combined_mapper_func)
    train_embryo_dataset_concat_mapped.epoch = epoch
    train_loader = torch.utils.data.DataLoader(train_embryo_dataset_concat_mapped,
                                               batch_size=batch_size, shuffle=True, num_workers=num_workers)

    return train_loader, scheduler, optimizer

if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('--input_dataset_folder', "-i", type=str, required=True, help = "path to folder with train datasets generated by "
                                                                                        "create_phenotype_datasets.py")
    parser.add_argument('--start_epoch', type=int, default=0 , help="start epoch. used in augmentation mappers")
    parser.add_argument('--save_path', type=str, required=True, help="path to save model checkpoints")
    parser.add_argument('--num_classes', type = int, default=16, help = "number of classification outputs")
    parser.add_argument('--batch_size', type=int, default=100, help="batch size")
    parser.add_argument('--num_epochs', type=int, default=10, help="num epochs to train")
    parser.add_argument('--num_workers', type=int, default=8, help="num threads")
    parser.add_argument('--start_model', type=str, default = "", help="path to checkpoint.pth to load weights from")
    parser.add_argument('--severities', nargs="+", default = [25, 50, 75, 100], help="severities for classes with severities")

    parser.add_argument('--classes', nargs="+", default=["NORMAL", "NODAL", "BMP",
                                                         "WNT", "FGF", "SHH",
                                                         "PCP","RA","BOOM",
                                                         "UNKNOWN"], help="classes names")

    parser.add_argument('--classes_with_severities', nargs="+", default=[], help = "classes with severities" )

    args = parser.parse_args()
    save_path = args.save_path
    start_epoch = args.start_epoch
    num_workers = args.num_workers
    num_epochs = args.num_epochs
    batch_size = args.batch_size
    severities = list(map(int, args.severities))

    if start_epoch > 0:
        num_epochs = start_epoch + num_epochs

    writer = SummaryWriter(os.path.join(os.path.dirname(save_path), 'summary'))

    EmbryoNet2_model = get_model(args.start_model, num_classes=args.num_classes)

    train_balanced_embryoDatasetConcat = get_datasets(args.input_dataset_folder,
                                                      class_names=args.classes,
                                                      classes_with_severities=args.classes_with_severities,
                                                      severities = severities)
    num_mappers = 0
    scheduler = None
    optimizer = None
    for epoch in range(args.start_epoch, num_epochs):
        train_loader, scheduler, optimizer = map_augmentated_dataset(epoch, num_mappers,scheduler, optimizer)

        train(EmbryoNet2_model, "cuda", train_loader, optimizer, epoch)
        scheduler.step()
        torch.save(EmbryoNet2_model.state_dict(),
                    save_path + str(start_epoch + epoch) + "_.pth")
 
    writer.close()
